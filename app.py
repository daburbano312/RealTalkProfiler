from flask import Flask, render_template
from flask_socketio import SocketIO, emit
from threading import Thread
import os

from core.use_cases.transcribe_stream import TranscriptionUseCase
from infrastructure.audio.vosk_speech_to_text import VoskSpeechToText
from interfaces.audio.audio_streamer import AudioStreamer
from infrastructure.emotion.text_emotion_detector import TextEmotionAnalyzer
from infrastructure.emotion.keyword_extractor import KeywordExtractor
from infrastructure.ai.openai_recommendation_engine import OpenAIRecommendationEngine  # âœ… NUEVO
from dotenv import load_dotenv
load_dotenv()


# ğŸ§  MÃ³dulos de anÃ¡lisis
text_emotion_analyzer = TextEmotionAnalyzer()
keyword_extractor = KeywordExtractor()
openai_api_key = os.getenv("OPENAI_API_KEY")  # AsegÃºrate de definir esta variable de entorno


if not openai_api_key:
    raise ValueError("âŒ No se encontrÃ³ la variable de entorno OPENAI_API_KEY. Verifica tu archivo .env o el entorno.")

recommendation_engine = OpenAIRecommendationEngine(api_key=openai_api_key)

emotion_word_buffer = []
MAX_EMOTION_WORDS = 15

# ğŸ”§ ConfiguraciÃ³n de Flask
app = Flask(__name__,
            template_folder="presentation/web/templates",
            static_folder="presentation/web/static")

socketio = SocketIO(app, cors_allowed_origins="*")

# ğŸ”¤ TranscripciÃ³n
speech_to_text = VoskSpeechToText()
transcriber = TranscriptionUseCase(speech_to_text)

# ğŸ“ Procesamiento de audio
def handle_audio(audio_chunk):
    global emotion_word_buffer

    if speech_to_text.accept_waveform(audio_chunk):
        result = speech_to_text.get_result()
        text = result.get("text", "").strip()

        if text:
            print(f"âœ… Texto final: {text}")
            socketio.emit("transcription", text)

            # ğŸ§  Acumulamos palabras para anÃ¡lisis emocional (sin afectar transcripciÃ³n)
            words = text.split()
            emotion_word_buffer += words
            print(f"ğŸ§  Palabras acumuladas: {len(emotion_word_buffer)}")

            if len(emotion_word_buffer) >= MAX_EMOTION_WORDS:
                full_text = " ".join(emotion_word_buffer[:MAX_EMOTION_WORDS])

                # ğŸ­ EmociÃ³n
                emotion_result = text_emotion_analyzer.analyze(full_text)
                print(f"ğŸ­ EmociÃ³n detectada: {emotion_result['emotion']}")
                socketio.emit("emotion", emotion_result)

                # ğŸ”‘ Palabras clave
                keywords = keyword_extractor.extract_keywords(full_text)
                print(f"ğŸ”‘ Palabras clave: {keywords}")
                socketio.emit("keywords", {"keywords": keywords})

                # ğŸ“¢ Generar sugerencia
                suggestion = recommendation_engine.generate_advice(
                    emotion_result['emotion'],
                    keywords,
                    full_text
                )
                print(f"ğŸ“¢ Sugerencia generada: {suggestion}")
                socketio.emit("suggestion", {"text": suggestion})

                # ğŸ§¹ Limpiar buffer
                emotion_word_buffer = emotion_word_buffer[MAX_EMOTION_WORDS:]

# ğŸ™ï¸ Iniciar el streaming de audio
streamer = AudioStreamer(handle_audio)

# PÃ¡gina principal
@app.route("/")
def index():
    return render_template("index.html")

@socketio.on("connect")
def connect():
    print("âœ… Cliente conectado vÃ­a WebSocket")

# ğŸš€ Ejecutar servidor
if __name__ == "__main__":
    print("ğŸš€ Iniciando transcripciÃ³n en hilo separado...")
    thread = Thread(target=streamer.start_stream)
    thread.start()

    print("ğŸŒ Levantando servidor Flask + SocketIO en puerto 5000")
    socketio.run(app, debug=True)
