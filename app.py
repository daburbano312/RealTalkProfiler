from flask import Flask, render_template
from flask_socketio import SocketIO, emit
from threading import Thread
import os

from core.use_cases.transcribe_stream import TranscriptionUseCase
from infrastructure.audio.vosk_speech_to_text import VoskSpeechToText
from interfaces.audio.audio_streamer import AudioStreamer
from infrastructure.emotion.text_emotion_detector import TextEmotionAnalyzer
from infrastructure.emotion.keyword_extractor import KeywordExtractor
from infrastructure.ai.openai_recommendation_engine import OpenAIRecommendationEngine  # âœ… NUEVO
from dotenv import load_dotenv
load_dotenv()

# ğŸ§  MÃ³dulos de anÃ¡lisis
text_emotion_analyzer = TextEmotionAnalyzer()
keyword_extractor = KeywordExtractor()
openai_api_key = os.getenv("OPENAI_API_KEY")  # AsegÃºrate de definir esta variable de entorno

if not openai_api_key:
    raise ValueError("âŒ No se encontrÃ³ la variable de entorno OPENAI_API_KEY. Verifica tu archivo .env o el entorno.")

recommendation_engine = OpenAIRecommendationEngine(api_key=openai_api_key)

emotion_word_buffer = []
MAX_EMOTION_WORDS = 15

# ğŸ”§ ConfiguraciÃ³n de Flask
app = Flask(__name__,
            template_folder="presentation/web/templates",
            static_folder="presentation/web/static")
socketio = SocketIO(app, cors_allowed_origins="*")

# ğŸ”¤ TranscripciÃ³n
speech_to_text = VoskSpeechToText()
transcriber = TranscriptionUseCase(speech_to_text)

# Variable global para el hilo de grabaciÃ³n
recording_thread = None
recording_active = False  # Bandera para controlar si se estÃ¡ grabando

# ğŸ“ Procesamiento de audio
def handle_audio(audio_chunk):
    global emotion_word_buffer, recording_active

    if not recording_active:
        # Si la grabaciÃ³n fue detenida, ignoramos el procesamiento
        return

    if speech_to_text.accept_waveform(audio_chunk):
        result = speech_to_text.get_result()
        text = result.get("text", "").strip()

        if text:
            print(f"âœ… Texto final: {text}")
            socketio.emit("transcription", text)

            # ğŸ§  Acumulamos palabras para anÃ¡lisis emocional (sin afectar transcripciÃ³n)
            words = text.split()
            emotion_word_buffer += words
            print(f"ğŸ§  Palabras acumuladas: {len(emotion_word_buffer)}")

            if len(emotion_word_buffer) >= MAX_EMOTION_WORDS:
                full_text = " ".join(emotion_word_buffer[:MAX_EMOTION_WORDS])

                # ğŸ­ EmociÃ³n
                emotion_result = text_emotion_analyzer.analyze(full_text)
                print(f"ğŸ­ EmociÃ³n detectada: {emotion_result['emotion']}")
                socketio.emit("emotion", emotion_result)

                # ğŸ”‘ Palabras clave
                keywords = keyword_extractor.extract_keywords(full_text)
                print(f"ğŸ”‘ Palabras clave: {keywords}")
                socketio.emit("keywords", {"keywords": keywords})

                # ğŸ“¢ Generar sugerencia
                suggestion = recommendation_engine.generate_advice(
                    emotion_result['emotion'],
                    keywords,
                    full_text
                )
                print(f"ğŸ“¢ Sugerencia generada: {suggestion}")
                socketio.emit("suggestion", {"text": suggestion})

                # ğŸ§¹ Limpiar buffer
                emotion_word_buffer = emotion_word_buffer[MAX_EMOTION_WORDS:]

# ğŸ™ï¸ Iniciar el streaming de audio
streamer = AudioStreamer(handle_audio)

# PÃ¡gina principal
@app.route("/")
def index():
    return render_template("index.html")

@socketio.on("connect")
def connect():
    print("âœ… Cliente conectado vÃ­a WebSocket")

@socketio.on("start_recording")
def start_recording():
    global recording_thread, recording_active
    if not recording_active:
        recording_active = True
        print("ğŸš€ Iniciando grabaciÃ³n...")
        recording_thread = Thread(target=streamer.start_stream)
        recording_thread.start()
        emit("status", {"message": "GrabaciÃ³n iniciada."})
    else:
        emit("status", {"message": "La grabaciÃ³n ya estÃ¡ en curso."})

@socketio.on("stop_recording")
def stop_recording():
    global recording_active
    if recording_active:
        print("â¹ï¸ Deteniendo grabaciÃ³n...")
        recording_active = False
        streamer.stop_stream()
        emit("status", {"message": "GrabaciÃ³n detenida."})
    else:
        emit("status", {"message": "No hay grabaciÃ³n en curso."})

# ğŸš€ Ejecutar servidor
if __name__ == "__main__":
    print("ğŸŒ Levantando servidor Flask + SocketIO en puerto 5000")
    socketio.run(app, debug=True)
