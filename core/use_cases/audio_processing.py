from infrastructure.audio.audio_recorder import PyAudioRecorder
from infrastructure.audio.vosk_speech_to_text import VoskSpeechToText
from core.entities.transcription import Transcription
from core.use_cases.emotion_analysis import EmotionAnalysisUseCase
from datetime import datetime
import threading

class AudioProcessingUseCase:
    def __init__(self):
        self.recorder = PyAudioRecorder()
        self.stt_service = VoskSpeechToText()
        self.emotion_analysis_use_case = EmotionAnalysisUseCase()

    # ğŸ”´ MODO INTERACTIVO (para consola)
    def process_audio(self) -> Transcription:
        print("ğŸ™ï¸ Preparado para grabar...")
        input("ğŸ”´ Presiona ENTER para comenzar a grabar...")

        thread = threading.Thread(target=self.recorder.start_recording)
        thread.start()

        input("â–¶ï¸ Grabando... Presiona ENTER para detener.\n")
        self.recorder.stop_recording()
        print("âœ… Stop de grabaciÃ³n ejecutado")

        thread.join()
        print("âœ… Hilo finalizado")

        audio_data = self.recorder.get_full_recording()
        print("ğŸ“¦ Bytes de audio grabados:", len(audio_data))

        with open("grabacion.wav", "wb") as f:
            f.write(audio_data)
        print("ğŸ’¾ Audio guardado como 'grabacion.wav'")

        text = self.stt_service.transcribe(audio_data)
        print("ğŸ“ Texto transcrito:", text)

        emotion_analysis = self.emotion_analysis_use_case.analyze_audio_and_text(audio_data, text)
        print("ğŸ“¤ Emociones detectadas:", emotion_analysis)

        transcription = Transcription(
            text=text,
            emotion_analysis=emotion_analysis,
            audio_duration=len(audio_data) / (self.recorder.rate * 2),
            timestamp=datetime.now()
        )
        return transcription

    # ğŸ” MODO AUTOMÃTICO (para API)
    def process_audio_automatic(self, seconds=6) -> Transcription:
        print(f"ğŸ™ï¸ Grabando automÃ¡ticamente por {seconds} segundos...")
        self.recorder.record_for(seconds=seconds)

        audio_data = self.recorder.get_full_recording()
        print("ğŸ“¦ Bytes de audio grabados:", len(audio_data))

        with open("grabacion.wav", "wb") as f:
            f.write(audio_data)
        print("ğŸ’¾ Audio guardado como 'grabacion.wav'")

        text = self.stt_service.transcribe(audio_data)
        print("ğŸ“ Texto transcrito:", text)

        emotion_analysis = self.emotion_analysis_use_case.analyze_audio_and_text(audio_data, text)
        print("ğŸ“¤ Emociones detectadas:", emotion_analysis)

        transcription = Transcription(
            text=text,
            emotion_analysis=emotion_analysis,
            audio_duration=len(audio_data) / (self.recorder.rate * 2),
            timestamp=datetime.now()
        )
        return transcription
